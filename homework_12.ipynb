{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torchvision.transforms as transforms  \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data for node 1 succesfully created\n",
      "data for node 2 succesfully created\n",
      "data for node 3 succesfully created\n"
     ]
    }
   ],
   "source": [
    "parent_dir = \"D:\\Training\\itHillel\\Machine Learning\\Lesson_12\\celeba\"\n",
    "celeba_raw_folder = os.path.join(\"Celeba_raw\", \"raw\")\n",
    "img_dir = os.path.join(parent_dir, celeba_raw_folder, \"img_align_celeba\") + os.sep\n",
    "out_dir = os.path.join(parent_dir, \"celeba_preprocessed\")\n",
    "\n",
    "columns = [\"Smiling\"]\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(parent_dir, celeba_raw_folder, \"list_attr_celeba.txt\"),\n",
    "    sep=\"\\s+\",\n",
    "    skiprows=1,\n",
    "    usecols=columns,\n",
    ")\n",
    "\n",
    "\n",
    "df.loc[df[\"Smiling\"] == -1, \"Smiling\"] = 0\n",
    "\n",
    "\n",
    "length = len(df)\n",
    "data_node_1 = df.iloc[: int(length / 3)]\n",
    "data_node_2 = df.iloc[int(length / 3) : int(length / 3) * 2]\n",
    "data_node_3 = df.iloc[int(length / 3) * 2 :]\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_1\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_1\", \"data\"))\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_2\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_2\", \"data\"))\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_3\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_3\", \"data\"))\n",
    "\n",
    "\n",
    "data_node_1.to_csv(os.path.join(out_dir, \"data_node_1\", \"target.csv\"), sep=\"\\t\")\n",
    "data_node_2.to_csv(os.path.join(out_dir, \"data_node_2\", \"target.csv\"), sep=\"\\t\")\n",
    "data_node_3.to_csv(os.path.join(out_dir, \"data_node_3\", \"target.csv\"), sep=\"\\t\")\n",
    "\n",
    "\n",
    "for im in data_node_1.index:\n",
    "    shutil.copy(img_dir + im, os.path.join(out_dir, \"data_node_1\", \"data\", im))\n",
    "print(\"data for node 1 succesfully created\")\n",
    "\n",
    "for im in data_node_2.index:\n",
    "    shutil.copy(img_dir + im, os.path.join(out_dir, \"data_node_2\", \"data\", im))\n",
    "print(\"data for node 2 succesfully created\")\n",
    "\n",
    "for im in data_node_3.index:\n",
    "    shutil.copy(img_dir + im, os.path.join(out_dir, \"data_node_3\", \"data\", im))\n",
    "print(\"data for node 3 succesfully created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, partition_file_path, root_dir, transform=None):\n",
    "        df = pd.read_csv(partition_file_path, sep=\"\\t\", index_col=0)\n",
    "        self.root_dir = root_dir\n",
    "        self.partition_file_path = partition_file_path\n",
    "        self.img_names = df.index.values\n",
    "        self.y = df['Smiling'].values\n",
    "        self.transform = transform\n",
    "        print(\"celeba dataset finished\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.asarray(Image.open(os.path.join(self.root_dir, self.img_names[index])))\n",
    "        img = transforms.ToTensor()(img)\n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celeba dataset finished\n",
      "celeba dataset finished\n"
     ]
    }
   ],
   "source": [
    "data_root = \"D:\\Training\\itHillel\\Machine Learning\\Lesson_12\\celeba\\celeba_preprocessed\"\n",
    "trainset = CelebADataset(f\"{data_root}/data_node_2/target.csv\", f\"{data_root}\\data_node_2\\data\")\n",
    "testset = CelebADataset(f\"{data_root}/data_node_3/target.csv\", f\"{data_root}\\data_node_3\\data\")\n",
    "\n",
    "trainloader = DataLoader(trainset, shuffle=True)\n",
    "testloader = DataLoader(testset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(3168, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=3168, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': {'batch_size': 32}, \n",
    "    'optimizer_args': {'lr': 1e-3},\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=training_args[\"optimizer_args\"][\"lr\"]\n",
    ")\n",
    "batch_size = training_args[\"loader_args\"][\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        pred = model(X)\n",
    "        loss_res = loss(pred, y)\n",
    "        loss_res.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "\n",
    "            loss_res, current = loss_res.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss_res:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model):\n",
    "    \n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\functional.py:154: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.684366  [    1/   83]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.686815  [    1/   83]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.696116  [    1/   83]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.697665  [    1/   83]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.679308  [    1/   83]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.691869 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 0.694014 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.689092 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 48.8%, Avg loss: 0.692979 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.691499 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    test_loop(testloader, model)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
